---
layout: post
title:  "How To Choose The Right Regression Model"
date:   2022-09-20
author: Scotty Zambrano
description: Choosing the correct regression model for your data and desired outcome.
image: /assets/images/Linear Regression.png
---

# What is regression and why should I care?

Regression is a type of statistical modeling that describes the relationship between a dependent variable (a.k.a. the target variable) and independent variables (a.k.a. predictor variables). The most common use of regression is identifying the influence that variables have on one another and then utilizing that to predict future outcomes. 

The tricky part about regression is there are many different types, which are all meant for specific kinds of data. If one were to use an incorrect type of regression on a certain dataset then the model would not fit well, leading to incorrect outcomes. In this post I will explain the process of choosing the correct type of regression. The best way to do this is to first pay attention to your dependent (target) variable and identify if it is continuous, categorical, or some type of counting variable. 

This post will be organized by the data type of the dependent variable. You can find sub-headings for continuous, categorical, and counting dependent variables. Under each sub-heading, you can find multiple types of regression to best fit your data. 

# Dependent Variables:

## 1. Continuous Dependent Variables

If your dependent variable is continuous such as weight, distance, or size.

### Simple Linear Regression - 
Simple Linear Regression is the basic ground work for other, more complicated, types of regression. Use this when there seems to be a linear relationship between an independent variable and a continuous dependent variable. This model clarifies the mean change in the dependent variables per one unit change in the independent variable. This is done by putting a line through the data with that minimizes the sum of the squared errors on either side. This method makes simple linear regression easily influenced by outliers, which means this may not fit the data well when using large amounts of data containing outliers. 

### Multiple Linear Regression - 
Similar to Simple Linear Regression, this type of regression differs in estimating the relationship between one dependent variable and two or more independent variables. The dependent still needs to be continuous but the independent variables can be either continuous or categorical and the data will be modeled similarly to Simple Linear Regression. When using Multiple Linear Regression, be aware of multicollinearity within the independent variables as this may undermine the significance of the variables. 

### Ridge Regression - 
Ridge Regression is the best method to use when the data does have high multicollinearity because it uses a regularization technique to reduce the complexity of the model. This eliminates a lot of the variance, caused by multicollinearity, but introduces a small amount of bias in the estimates. Ridge Regression models the data by adding an "L2 penalty" which essentially shrinks all of the coefficients by the same factor, resulting in none of the coefficients being eliminated. 

### Lasso Regression - 
Lasso Regression is very similar to Ridge Regression but it offers a way to do variable selection. This is done by prohibiting the size of the coefficient, causing the values to become closer to zero. Lasso Regression enhances the prediction accuracy and allows the model to become more interpretable. 

### Partial Least Squares Regression - 
Partial Least Squares Regression is used when the data has high multicollinearity or when you have a small amount of observations compared to the number of independent variables. It works by decreasing the independent variables down to a few uncorrelated components, then running linear regression on these components. An interesting aspect of Partial Least Squares Regression is one can include multiple dependent variables as long as they are all continuous.  




